{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UR12IzmtGuQ7"
   },
   "source": [
    "\n",
    "\n",
    "# [Fine-Tuning Local Models with LoRA in Python](https://https://www.youtube.com/watch?v=XDOSVh9jJiA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9A91k2SfGs5s",
    "outputId": "fdc929ce-b28f-43d2-f65f-de22b7c72205"
   },
   "outputs": [],
   "source": [
    "!pip install -U bitsandbytes datasets accelerate loralib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qlqD1Di4Hxra"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hy_-bJWDElE1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-F1aStrWHGx7"
   },
   "outputs": [],
   "source": [
    "# Run the installation command again to ensure bitsandbytes is installed\n",
    "# and updated to the latest version.\n",
    "#!pip install -U bitsandbytes\n",
    "\n",
    "# It is good practice to restart the kernel after installing new packages,\n",
    "# especially if there are environment-related issues.\n",
    "# If you are in a Jupyter environment, you can restart the kernel from the menu.\n",
    "# If you are running this script directly, you might need to re-run the script.\n",
    "\n",
    "# After restarting the kernel (if necessary), rerun the imports and the model loading code.\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "model_name = 'TinyLLama/TinyLlama-1.1B-Chat-v1.0'\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = 'nf4',\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config = bnb_config,\n",
    "    device_map = 'auto',\n",
    "    trust_remote_code = True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56RrixLRHHOa"
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r = 8,\n",
    "    lora_alpha = 16,\n",
    "    target_modules = ['q_proj', 'v_proj'],\n",
    "    lora_dropout = 0.05,\n",
    "    bias = 'none',\n",
    "    task_type = TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ABZ_VuZmI-_Q",
    "outputId": "44631198-68e7-441e-b22c-07acb32dec6d"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade fsspec\n",
    "!pip install datasets==2.12.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "fb15e8c4a2f74a10b968e436387cb63b",
      "dffe7f79609e4c61b7c363ee111026f7",
      "e670f8853a1b4c62b664b64230d35374",
      "f93f99f986084be98d3564e09565ea30",
      "5e028ce2459848529e4f3386281fd47c",
      "224ae4f3fbc1485f9c71a0db6bc8fd87",
      "50ef9b25feed4ee5b3b99ac0d515e130",
      "8ecb9472e9004102b12747c2e1097ba8",
      "a82e323eb871485e99dcb772bbff0e6a",
      "792660d78fe8478da7eab2e6a04f409b",
      "3c20f4005e2b466db5d17bea1b6a5fde",
      "dfd8af7576a94ded831d3f2484164e44",
      "931440facd7448cea201cf3e787f39c0",
      "8bbc9c56226e46d08580256930aa619b",
      "fb5af742d8284b1b8ddab7d1dd00ad1f",
      "c1e884c837964b6bb120a791add763b2",
      "59330cdb0399427a9472b2536da3c9c6",
      "859373b751b24ef587aecdc4031e441e",
      "f79a394161d84094a48e22d51f1b1938",
      "d1a74f2c5c964b7cb75af3758f01ea70",
      "4a43bd1405f047ecb6e49594e60bc40f",
      "7cde59dac0ec46cd879b76b28f0842e6",
      "dff6517c2cdd4f5a81c1c89e19753a0f",
      "0cb5a97ea6374b85acb02f98a39ffb82",
      "077601fbea9f458bb66f323e1e9306a9",
      "f0c0d5a574a84049ace3918dd8add621",
      "4c0ec7bd258947b6845584bc36c12514",
      "41e0f693645a40cca39fc5ac55dd170d",
      "3bcd788c5e664e4d8d92401b553ceb27",
      "289eb0e1736b4b0baf3e688a2e1700b3",
      "4c660a60b5ca43d58d5f12a5d89d853e",
      "fd3546b1c8ad421e8374587c9bb8ec20",
      "dbf4390847a941e39441d3bd57fa271b",
      "7797fbe35ef441ce8018f3d35c755245",
      "7990a95af48b468eba13c60c6136fc47",
      "82888b9d1d2b494fa58c3444bb998e73",
      "4a0dc9dfe3e245c48d19b95d00bc8c0f",
      "ee081632232b4ca8bc42ce74baf48077",
      "baad6108b0f345c78c1029ca71fa8993",
      "3c2ef2fd19f54882a12410cd2f98127d",
      "84a3584e7917475ea57a4ae6fc84c67f",
      "9f66fba5ba024731850c3c728914010f",
      "3f0b34c4a96f4646a4db000ce40b953b",
      "097145642f3c45edb1811cbd8b77a683",
      "b6e7e785f26a4b7b8b742aad2f0c2fa7",
      "9791dc14e18844c8bcdeaefda25f8032",
      "a9f6a26c98be46d69f54e2b40d638143",
      "ea9e8e58cb0b4bd8a9fc635a4dccc37e",
      "32438b91085a4edba4a2ede38a032252",
      "12fbb8627f244e079d61b444b4c402b1",
      "4db86158aea04d8093109ff3856042db",
      "a5bdd33721964e0f84871e2a58a335c0",
      "6c738ada97c845dfaa0c0fe258ed0035",
      "033b4a042c9741a2ae1f451fea7a383d",
      "6ad44a54af954faaa11d6b1203e48477"
     ]
    },
    "id": "jnxP6yoXISko",
    "outputId": "dff05dcd-6939-434c-ddc9-7451145c4cfb"
   },
   "outputs": [],
   "source": [
    "\n",
    "data = load_dataset('openai/gsm8k', 'main', split='train[:200]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_MwBM5QbIXt4"
   },
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    texts = [\n",
    "        f\"### Instruction:\\n{inst}\\n### Response:\\n{out}\"\n",
    "        for inst, out in zip(batch['question'], batch['answer'])\n",
    "    ]\n",
    "\n",
    "    tokens = tokenizer(\n",
    "        texts,\n",
    "        padding = 'max_length',\n",
    "        truncation = True,\n",
    "        max_length = 256,\n",
    "        return_tensors = 'pt'\n",
    "    )\n",
    "\n",
    "    tokens['labels'] = tokens['input_ids'].clone()\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "84db5ecddbf146f8b757dae4b7d9333a",
      "7bf92c78415e44f3ac91e131691af714",
      "6765a8a38adf4239b1ed9789057f6f4e",
      "0f3839cf32b0499caae20868d302adc9",
      "0392ec7da5bd483480c410d9ef59283a",
      "14fca1e9ae5c43bc8aea927712eb58c2",
      "caf4b3e2df674d83b94f8a16dcee8217",
      "89d3e25ba134460ab037fd465e13d4f3",
      "67c78fd15667417abf8e691efa6de262",
      "5876848be0c7427f8001ff776850e867",
      "2426aa963c4d4f6e85609e929bddca1a"
     ]
    },
    "id": "4FkH54IWJgvn",
    "outputId": "75013e03-ba32-4562-82dd-673daefc02bb"
   },
   "outputs": [],
   "source": [
    "\n",
    "tokenized_data = data.map(tokenize, batched=True, remove_columns=data.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibuA19UBJgsJ"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = './tinyllama-lora-tuned',\n",
    "    per_device_train_batch_size = 4,\n",
    "    gradient_accumulation_steps = 4,\n",
    "    learning_rate = 1e-3,\n",
    "    num_train_epochs = 50,\n",
    "    fp16 = True,\n",
    "    logging_steps = 20,\n",
    "    save_strategy = 'epoch',\n",
    "    report_to = 'none',\n",
    "    remove_unused_columns = False,\n",
    "    label_names = [\"labels\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3YFNDCMJgpX"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_data,\n",
    "    processing_class = tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "r0usgBcwJgmX",
    "outputId": "4c78b386-3431-40f3-eb59-8f1ef4f143d8"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZa8wURVJgjX",
    "outputId": "25e2f7d2-f442-4707-ee66-1168f6d03c72"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./tinyllama-lora-tuned-adapter-math\")\n",
    "tokenizer.save_pretrained(\"./tinyllama-lora-tuned-adapter-math\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OEV8o13QCRG"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GKRY8aA_Jggg",
    "outputId": "5f6a60a2-b800-412a-fd44-83867e3f13dd"
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "model_name = 'TinyLLama/TinyLlama-1.1B-Chat-v1.0'\n",
    "adapter_path = './tinyllama-lora-tuned-adapter-math'\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = 'nf4',\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config = bnb_config,\n",
    "    device_map = 'auto',\n",
    "    trust_remote_code = True\n",
    ").eval()\n",
    "\n",
    "tmp_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config = bnb_config,\n",
    "    device_map = 'auto',\n",
    "    trust_remote_code = True\n",
    ")\n",
    "\n",
    "tuned_model = PeftModel.from_pretrained(tmp_model, adapter_path)\n",
    "tuned_model = tuned_model.merge_and_unload().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kdEFLlzNNy0J"
   },
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    texts = [\n",
    "        f\"### Instruction:\\n{inst}\\n### Response:\\n{out}\"\n",
    "        for inst, out in zip(batch['question'], batch['answer'])\n",
    "    ]\n",
    "\n",
    "    tokens = tokenizer(\n",
    "        texts,\n",
    "        padding = 'max_length',\n",
    "        truncation = True,\n",
    "        max_length = 256,\n",
    "        return_tensors = 'pt'\n",
    "    )\n",
    "\n",
    "    tokens['labels'] = tokens['input_ids'].clone()\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c5796b8b052049498a9511a17a4f3375",
      "e2a82187cffb4b74b6347651c76585ac",
      "2d6566b203e5483cb84e877af1335537",
      "c4c6b670d8ab489187fdff5816e052f4",
      "07a951e8befa4a448ef7a8fc8cc1972a",
      "8c4be70baf7844f59eb8ef07c80e618c",
      "7f19b8441524456b82927d7bbb851a87",
      "080330629f4e494194824f46c5f2abd7",
      "6856dbb9975f4d68855885c49b7fc4d9",
      "7c5058a602834f4e910656cc23f7c6d2",
      "7c775bff883b4cd081309b76946d7263"
     ]
    },
    "id": "LmFuW9IgOE-I",
    "outputId": "af1ec7bc-0846-4bcf-b7b1-38b7b2a62fe6"
   },
   "outputs": [],
   "source": [
    "eval_ds = load_dataset('openai/gsm8k', 'main', split='train[:20]')\n",
    "eval_ds = eval_ds.map(tokenize, batched=True, remove_columns=['question', 'answer'])\n",
    "eval_ds = eval_ds.with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBd1IJXiOIFQ"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, default_data_collator\n",
    "eval_loader = DataLoader(\n",
    "    eval_ds,\n",
    "    batch_size = 8,\n",
    "    collate_fn = default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faa3x9EWOLxY"
   },
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def compute_perplexity(model):\n",
    "    import math\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for batch in eval_loader:\n",
    "        batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "        loss = model(**batch).loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return math.exp(sum(losses) / len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ntTyhlTLO1KH",
    "outputId": "0f1e1aad-736c-411e-a387-7016f62704b6"
   },
   "outputs": [],
   "source": [
    "print(f'Base Model Perplexity: {compute_perplexity(base_model):.2f}')\n",
    "print(f'Tuned Model Perplexity: {compute_perplexity(tuned_model):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "6a132b0abe1248d4ab131f0d7e317bbd",
      "ef85e13b2af84d549826504e7ad810d5",
      "049dbd5cfed04a389f54279214192a4e",
      "56cf3ad7ee074ed699981048acd7d087",
      "7604dd7fbfc7478fbad8f11dacfa15b6",
      "a1a5997c03394baebd6b500da4f090d2",
      "da1618ad0c134b38bbb1fd707ce70934",
      "54430b758cd147768b16980bbcc85c3f",
      "29fd2aac01f1402582c56b42739662ab",
      "996dce74bc784210b8b3b236f6070119",
      "d1a028dd750b48d79aad8179c6ad2700",
      "ab97304bf6ef464ebe9e550e2c6bbaf0",
      "894598fccafb4fdbaee151e8ed186646",
      "feb20fdf44f74c4d995c77e13ac1a0db",
      "10fba4727f1041d59fed06d200c4f90d",
      "2732bf7f647c48408d40aef4b9e06bcd",
      "6d4b7f1729ec406a9fd0ae0f3020449d",
      "2d3a0b3f988140a6897983d7f245e821",
      "4467c99b48644591a23daad6b13de467",
      "436d451d818d4cfeb527597d2513a1b3",
      "c6b1455fd1cd4f499567b7359213be2b",
      "6deb6387f82549b5a0ebff263b5ce6c0",
      "c776b649d03046a09a2d4b18aaaaa891",
      "54fb4db21e2e43ce9d5fe079c6f63331",
      "1b789ce01e954ac3902a12bb49507248",
      "352a3e49741d4dac8b51474a3cff51fb",
      "061367c67905442582fca225b95de1aa",
      "009cceea975649cebde161537b9872c2",
      "75064379e41a496f975447a0ebd9a6cb",
      "61edcb74e2ca48daa3759a45bd548347",
      "56bb95a227fe4a6f8ec2dda7fa8b29c1",
      "00c676aeb0e949aeb1e96814e6f243bc",
      "d61bc5e1a01e4e7fa66ba9c32de549d2",
      "50cb7c23097541aca7235755744a0f37",
      "ac4a2068e4f948c8bc8b835ab337e582",
      "a1d9ed2268a845c5a7c8f33421887a68",
      "a9107bf2127c4536b69773690851f580",
      "014032e7b01548589f105ee7f0ec05e5",
      "630f069e306e4b9a878916ab524fbf0d",
      "705cff129bbb4b1eaedf6c184e907a63",
      "496e869a51964f8ebedba0922388a9ed",
      "2393798e2afa4d288792ca4f3927f237",
      "8ebb16477aaa433e829c69358607e566",
      "0b4a808966e34609ad2475bc08418e7b",
      "af405a5c6d7144959efe975479b8e723",
      "dbce467b7d5c47f3b4fad6f808469f80",
      "52ce937f1c7d4a0bb1e55d2e1f20dc27",
      "9bd05256930446a0aea0deab6ab958ce",
      "5dcaefa04ca84544a8ce88fd7e4669c5",
      "c63ab106d60f4a499529db4415ba5885",
      "d6d080195f004cca84f7ed5f66c57938",
      "9034d215f57a44979889f69f6c601e24",
      "3f7ec05aefa04416b4deaf6825eb39a0",
      "b3e076e602414f9fa24b3b551395f975",
      "2a24a7bd31f64d18915f21396dd297ff"
     ]
    },
    "id": "u7c8QsUSO4_P",
    "outputId": "657e7eb4-19a1-45bb-ed22-9bfeffd0b0c3"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "raw_data = load_dataset('gsm8k', 'main', split='train[:20]')\n",
    "refs = raw_data['answer']\n",
    "\n",
    "\n",
    "def generate(model, instruction):\n",
    "    token_ids = tokenizer(f'### Instruction:\\n{instruction}\\n### Response:\\n', return_tensors='pt').input_ids.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(token_ids, max_new_tokens=256)\n",
    "\n",
    "    #return tokenizer.decode(out[0], skip_special_tokens=True).split('### Response:\\n')[-1].strip()\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "grHaqk5iPKr3",
    "outputId": "f06b626a-7204-4144-cfc3-3a9cc85ce7b7"
   },
   "outputs": [],
   "source": [
    "raw_data['question'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yk-KOgT5PQum",
    "outputId": "f93cf13c-bbe1-4dd3-faf3-2900ee2509b9"
   },
   "outputs": [],
   "source": [
    "print(generate(base_model, raw_data['question'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DzQPxnLcPmcW",
    "outputId": "59ae6292-4dcf-4b90-efe7-aa2f22940774"
   },
   "outputs": [],
   "source": [
    "print(generate(tuned_model, raw_data['question'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b22qUCs8Ppqm",
    "outputId": "2acd201a-c469-41f6-8807-00ee37345092"
   },
   "outputs": [],
   "source": [
    "print(refs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1_r8pLMP3Zf"
   },
   "source": [
    "## Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "93f329811fa64c0097d9c329513f6ad6",
      "b3e95ac63b60458894addeb106fe3c2a",
      "2ce5f6ea922f42cfada2c434afe427b2",
      "bf0dd4b1a34540e78739ed74e9dc02bc",
      "6376337f61434163a309e6ef98718526",
      "82819cb944d8446883c1b887eac6ac4d",
      "bc3e0e384ad2463cba42fff256d7b06e",
      "ab31265833fc45b9b144cddf75ab2aff",
      "ebbd7f53afe4427dbcc96c9c0f513549",
      "2572b6abf8b54d668d1725f0831a694a",
      "83b09f6d64f746288ca4254390e4e008"
     ]
    },
    "id": "NuutVXOiPwT-",
    "outputId": "87d8a601-6208-43ab-8949-c3e1dbb87525"
   },
   "outputs": [],
   "source": [
    "eval_ds = load_dataset('openai/gsm8k', 'main', split='train[200:300]')\n",
    "eval_ds = eval_ds.map(tokenize, batched=True, remove_columns=['question', 'answer'])\n",
    "eval_ds = eval_ds.with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0I6dLwePzem"
   },
   "outputs": [],
   "source": [
    "eval_loader = DataLoader(\n",
    "    eval_ds,\n",
    "    batch_size = 8,\n",
    "    collate_fn = default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VcKReNcBP9KF",
    "outputId": "4127b646-7422-4890-f15a-80784eb03fed"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(f'Base Model Perplexity: {compute_perplexity(base_model):.2f}')\n",
    "print(f'Tuned Model Perplexity: {compute_perplexity(tuned_model):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_a24vPURP_p9"
   },
   "outputs": [],
   "source": [
    "raw_data = load_dataset('gsm8k', 'main', split='train[200:300]')\n",
    "refs = raw_data['answer']\n",
    "\n",
    "\n",
    "def generate(model, instruction):\n",
    "    token_ids = tokenizer(f'### Instruction:\\n{instruction}\\n### Response:\\n', return_tensors='pt').input_ids.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(token_ids, max_new_tokens=256)\n",
    "\n",
    "    #return tokenizer.decode(out[0], skip_special_tokens=True).split('### Response:\\n')[-1].strip()\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "Ba7tzz2AQJfd",
    "outputId": "7aadee90-2657-4034-bc66-5892ea656de4"
   },
   "outputs": [],
   "source": [
    "raw_data['question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zbm97meCQMV9",
    "outputId": "60590d82-76c6-46d6-e21e-5837c11671a8"
   },
   "outputs": [],
   "source": [
    "print(generate(base_model, raw_data['question'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1wXbPMMEQOVd",
    "outputId": "fcc9b932-7846-4287-c82c-fb97a4526803"
   },
   "outputs": [],
   "source": [
    "print(generate(tuned_model, raw_data['question'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GJq2tJaJQSR1",
    "outputId": "834555b8-af41-4c04-e780-9d97468ec561"
   },
   "outputs": [],
   "source": [
    "print(refs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJNJeoW7QXAd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
